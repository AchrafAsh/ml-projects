{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from rnn_dataset import Vocabulary\n",
    "from torch.nn.utils.rnn import pad_sequence  # padding of every batch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, root_dir, filename, freq_threshold=1):\n",
    "        self.root_dir = root_dir\n",
    "        self.df = pd.read_csv(os.path.join(root_dir, filename))\n",
    "\n",
    "        self.sentiments = self.df[\"sentiment\"]\n",
    "        self.texts = self.df[\"text\"]\n",
    "\n",
    "        self.vocab = Vocabulary(freq_threshold)\n",
    "        self.vocab.build_vocab(self.texts.tolist())\n",
    "\n",
    "        self.vocab_size = len(self.vocab)\n",
    "\n",
    "    def __len__(self): return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoded_text = [self.vocab.stoi[\"<SOS>\"]]\n",
    "        encoded_text += [encoded_token for encoded_token \n",
    "                         in self.vocab.encode(self.texts[idx])]\n",
    "        encoded_text.append(self.vocab.stoi[\"<EOS>\"])\n",
    "\n",
    "        return {\"text\": torch.tensor(encoded_text).long(), \"sentiment\": torch.tensor(self.sentiments[idx])}\n",
    "\n",
    "class CollateBatch:\n",
    "    def __init__(self, padding_idx):\n",
    "        self.padding_idx = padding_idx\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        sentiments = [item[\"sentiment\"] for item in batch]\n",
    "        texts = [item[\"text\"] for item in batch]\n",
    "        texts = pad_sequence(texts, batch_first=False,\n",
    "                             padding_value=self.padding_idx)\n",
    "\n",
    "        return texts, torch.tensor(sentiments)\n",
    "\n",
    "\n",
    "def get_loader(root_dir, filename, batch_size=10, num_workers=1, shuffle=True, pin_memory=True):\n",
    "    dataset = SentimentDataset(root_dir, filename)\n",
    "    padding_idx = dataset.vocab.stoi[\"<PAD>\"]\n",
    "\n",
    "    loader = DataLoader(dataset=dataset, batch_size=batch_size, num_workers=num_workers,\n",
    "                        shuffle=shuffle, pin_memory=pin_memory, collate_fn=CollateBatch(padding_idx=padding_idx))\n",
    "    return loader, dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(RNNCell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.whh = nn.Linear(hidden_size, hidden_size)\n",
    "        self.wxh = nn.Linear(input_size, hidden_size)\n",
    "    \n",
    "    def forward(self, x, hidden_state): # x (batch_size, input_size)\n",
    "        return torch.sigmoid(self.whh(hidden_state) + self.wxh(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, input_size, vocab_size, embedding_size, hidden_size, output_size=2, padding_idx=0):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_size, padding_idx=padding_idx)\n",
    "        self.rnn1 = RNNCell(embedding_size, hidden_size)\n",
    "        self.rnn2 = RNNCell(hidden_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def init_hidden_state(self, batch_size):\n",
    "        return torch.zeros(batch_size, self.hidden_size)\n",
    "    \n",
    "    def forward(self, x, hidden_state): # x (seq_len, batch_size, input_size)\n",
    "        h1 = hidden_state\n",
    "        h2 = hidden_state\n",
    "        x = self.embeddings(x)\n",
    "\n",
    "        for i in range(x.shape[0]):\n",
    "            h1 = self.rnn1(x[i], h1)\n",
    "            h2 = self.rnn2(h1, h2)\n",
    "        \n",
    "        output = F.softmax(self.fc(h2), dim=1)\n",
    "        return output, hidden_state\n",
    "    \n",
    "    def fit(self, dataset, batch_size, epochs, lr=0.001):\n",
    "        self.train()\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=lr)\n",
    "        criterion = torch.nn.CrossEntropyLoss() # ignore_index=pad_idx?\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            for idx, (texts, sentiments) in enumerate(dataset):\n",
    "                hidden_state = self.init_hidden_state(batch_size=batch_size)\n",
    "                \n",
    "                # forward\n",
    "                for i in range(texts.shape[0]):\n",
    "                    output, hidden_state = self.forward(texts[i], hidden_state)\n",
    "                \n",
    "                loss = criterion(output, sentiments)\n",
    "                \n",
    "                # backward\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.parameters(), max_norm=1)\n",
    "                \n",
    "                # gradient descent or Adam step\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss\n",
    "            \n",
    "            accuracy = self.evaluate(dataset)\n",
    "            if (epoch % 10 == 0): print(f\"epoch [{epoch+1} / {epochs}] | total loss: {total_loss} | accuracy: {accuracy} \")\n",
    "    \n",
    "    def evaluate(self, dataset):\n",
    "        self.eval()\n",
    "        \n",
    "        accuracy = 0\n",
    "        \n",
    "        for idx, (texts, sentiments) in enumerate(dataset):\n",
    "            hidden_state = self.init_hidden_state(batch_size=1)\n",
    "            \n",
    "            # forward\n",
    "            for i in range(texts.shape[0]):\n",
    "                output, hidden_state = self.forward(texts[i], hidden_state)\n",
    "            \n",
    "            if (torch.argmax(output).item() == sentiments.item()): accuracy += 1\n",
    "        \n",
    "        return accuracy / len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=1\n",
    "HIDDEN_SIZE=12\n",
    "EMBED_SIZE=12\n",
    "OUTPUT_SIZE=2\n",
    "LR=0.01\n",
    "NUM_EPOCHS=400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADING THE DATA\n",
    "dataloader,dataset = get_loader(\"../data/\", \"small_sentiments.csv\", batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SentimentClassifier(input_size=dataset.vocab_size, hidden_size=HIDDEN_SIZE,\n",
    "                                vocab_size=len(dataset.vocab), embedding_size=EMBED_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1 / 400] | total loss: 2.8278090953826904 | accuracy: 0.5 \n",
      "epoch [11 / 400] | total loss: 2.814012050628662 | accuracy: 0.5 \n",
      "epoch [21 / 400] | total loss: 2.8038220405578613 | accuracy: 0.5 \n",
      "epoch [31 / 400] | total loss: 2.797112226486206 | accuracy: 0.5 \n",
      "epoch [41 / 400] | total loss: 2.792570114135742 | accuracy: 0.5 \n",
      "epoch [51 / 400] | total loss: 2.7894845008850098 | accuracy: 0.5 \n",
      "epoch [61 / 400] | total loss: 2.7876052856445312 | accuracy: 0.5 \n",
      "epoch [71 / 400] | total loss: 2.786376476287842 | accuracy: 0.5 \n",
      "epoch [81 / 400] | total loss: 2.7855350971221924 | accuracy: 0.5 \n",
      "epoch [91 / 400] | total loss: 2.7850241661071777 | accuracy: 0.5 \n",
      "epoch [101 / 400] | total loss: 2.78464937210083 | accuracy: 0.5 \n",
      "epoch [111 / 400] | total loss: 2.784529447555542 | accuracy: 0.5 \n",
      "epoch [121 / 400] | total loss: 2.7843949794769287 | accuracy: 0.5 \n",
      "epoch [131 / 400] | total loss: 2.784329414367676 | accuracy: 0.5 \n",
      "epoch [141 / 400] | total loss: 2.784271001815796 | accuracy: 0.5 \n",
      "epoch [151 / 400] | total loss: 2.784238338470459 | accuracy: 0.5 \n",
      "epoch [161 / 400] | total loss: 2.78422212600708 | accuracy: 0.5 \n",
      "epoch [171 / 400] | total loss: 2.784203052520752 | accuracy: 0.5 \n",
      "epoch [181 / 400] | total loss: 2.784130573272705 | accuracy: 0.5 \n",
      "epoch [191 / 400] | total loss: 2.784189224243164 | accuracy: 0.5 \n",
      "epoch [201 / 400] | total loss: 2.7841813564300537 | accuracy: 0.5 \n",
      "epoch [211 / 400] | total loss: 2.7841134071350098 | accuracy: 0.5 \n",
      "epoch [221 / 400] | total loss: 2.7841782569885254 | accuracy: 0.5 \n",
      "epoch [231 / 400] | total loss: 2.7841057777404785 | accuracy: 0.5 \n",
      "epoch [241 / 400] | total loss: 2.7841031551361084 | accuracy: 0.5 \n",
      "epoch [251 / 400] | total loss: 2.7841691970825195 | accuracy: 0.5 \n",
      "epoch [261 / 400] | total loss: 2.7841010093688965 | accuracy: 0.5 \n",
      "epoch [271 / 400] | total loss: 2.7841668128967285 | accuracy: 0.5 \n",
      "epoch [281 / 400] | total loss: 2.784097194671631 | accuracy: 0.5 \n",
      "epoch [291 / 400] | total loss: 2.784163475036621 | accuracy: 0.5 \n",
      "epoch [301 / 400] | total loss: 2.7841622829437256 | accuracy: 0.5 \n",
      "epoch [311 / 400] | total loss: 2.784160614013672 | accuracy: 0.5 \n",
      "epoch [321 / 400] | total loss: 2.7840921878814697 | accuracy: 0.5 \n",
      "epoch [331 / 400] | total loss: 2.7840919494628906 | accuracy: 0.5 \n",
      "epoch [341 / 400] | total loss: 2.784090995788574 | accuracy: 0.5 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-b6eaa19a159d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TRAINING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-9764b1d34e32>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, batch_size, epochs, lr)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"epoch [{epoch+1} / {epochs}] | total loss: {total_loss} | accuracy: {accuracy} \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-9764b1d34e32>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentiments\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0mhidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    929\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-2677:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/achraf/anaconda3/envs/pytorch/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/achraf/anaconda3/envs/pytorch/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/achraf/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/_utils/pin_memory.py\", line 25, in _pin_memory_loop\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/achraf/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 113, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/achraf/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 282, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/home/achraf/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/home/achraf/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/home/achraf/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py\", line 493, in Client\n",
      "    answer_challenge(c, authkey)\n",
      "  File \"/home/achraf/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py\", line 732, in answer_challenge\n",
      "    message = connection.recv_bytes(256)         # reject large message\n",
      "  File \"/home/achraf/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/achraf/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/achraf/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRAINING\n",
    "classifier.fit(dataloader, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(classifier, vocab, sentence):\n",
    "    vocab_size = len(vocab)\n",
    "    \n",
    "    \n",
    "    encoded_text = []\n",
    "    encoded_text.append([vocab.stoi[\"<SOS>\"]])\n",
    "    encoded_text += [[encoded_token]\n",
    "                     for encoded_token in vocab.encode(sentence)]\n",
    "    encoded_text.append([vocab.stoi[\"<EOS>\"]])\n",
    "\n",
    "    encoded_text = torch.tensor(encoded_text).long()\n",
    "    print(encoded_text.shape)\n",
    "    h0 = classifier.init_hidden_state(batch_size=1)\n",
    "\n",
    "    for i in range(encoded_text.shape[0]):\n",
    "        output, h0 = classifier(encoded_text[i], h0)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1])\n",
      "tensor([[0.4992, 0.5008]], grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([5, 1])\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "classifier.eval()\n",
    "print(get_sentiment(classifier, dataset.vocab, \"I hate you\"))\n",
    "print(torch.argmax(get_sentiment(classifier, dataset.vocab, \"I love you\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
