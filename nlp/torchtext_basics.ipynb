{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEPS\n",
    "\n",
    "1. specify how preprocessing should be done\n",
    "2. use Dataset to load the data (tabular dataset)\n",
    "3. construct an iterator for batch & padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field, TabularDataset, BucketIterator\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def tokenize(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/achraf/anaconda3/envs/pytorch/lib/python3.6/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "tokenize = lambda x: x.split()\n",
    "quote = Field(sequential=True, use_vocab=True,\n",
    "              tokenize=tokenize, lower=True)\n",
    "score = Field(sequential=False, use_vocab=False)\n",
    "\n",
    "fields = {'quote': ('q', quote), 'score': ('s', score)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/achraf/anaconda3/envs/pytorch/lib/python3.6/site-packages/torchtext/data/example.py:13: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = TabularDataset.splits(\n",
    "                            path=\"data\", train=\"motivation.json\",\n",
    "                            test=\"motivation.json\", format=\"json\",\n",
    "                            # validation=\"motivation.json\", \n",
    "                            fields=fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/achraf/anaconda3/envs/pytorch/lib/python3.6/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "quote.build_vocab(train_data, max_size=10000,\n",
    "                 # vectors=\"glove.68.100d\" # 1GB\n",
    "                  min_freq=1)\n",
    "train_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, test_data),\n",
    "    batch_size=2,\n",
    "    device=\"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Built in Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python: No module named spacy\n",
      "/usr/bin/python: No module named spacy\n"
     ]
    }
   ],
   "source": [
    "spacy_en = spacy.load('en')\n",
    "spacy_de = spacy.load('de')\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "def tokenize_de(text):\n",
    "    return [tok.text for tok in spacy_de.tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenize_en' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5691521936bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m english = Field(sequential=True, use_vocab=True,\n\u001b[0;32m----> 2\u001b[0;31m                tokenize=tokenize_en, lower=True)\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenize_en' is not defined"
     ]
    }
   ],
   "source": [
    "english = Field(sequential=True, use_vocab=True,\n",
    "               tokenize=tokenize_en, lower=True)\n",
    "\n",
    "deutsch = Field(sequential=True, use_vocab=True,\n",
    "               tokenize=tokenize_de, lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data, test_data = Multi30k.splits(\n",
    "    exts=('.de', '.en'), fields=(deutsch, english))\n",
    "\n",
    "english.build_vocab(train_data, max_size=10000, min_freq=2)\n",
    "deutsch.build_vocab(train_data, max_size=10000, min_freq=2)\n",
    "\n",
    "train_iterator, validation_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, validation_data, test_data),\n",
    "    batch_size=64,\n",
    "    device='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_iterator:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "english.vocab.stoi['the']\n",
    "\n",
    "\\> 5\n",
    "\n",
    "english.vocab.itos[5]\n",
    "\n",
    "\\> 'the'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
