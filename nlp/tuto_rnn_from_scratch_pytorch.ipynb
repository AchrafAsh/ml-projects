{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from string import ascii_letters\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from unidecode import unidecode\n",
    "\n",
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data/names\"\n",
    "\n",
    "lang2label = {\n",
    "    file_name.split(\".\")[0]: torch.tensor([i], dtype=torch.long)\n",
    "    for i, file_name in enumerate(os.listdir(data_dir))\n",
    "}\n",
    "num_langs = len(lang2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2idx = {letter: i for i, letter in enumerate(ascii_letters + \" .,:;-'\")}\n",
    "num_letters = len(char2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name2tensor(name):\n",
    "    tensor = torch.zeros(len(name), 1, num_letters)\n",
    "    for i, char in enumerate(name):\n",
    "        tensor[i][0][char2idx[char]] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_names = []\n",
    "target_langs = []\n",
    "\n",
    "for file in os.listdir(data_dir):\n",
    "    with open(os.path.join(data_dir, file)) as f:\n",
    "        lang = file.split(\".\")[0]\n",
    "        names = [unidecode(line.rstrip()) for line in f]\n",
    "        for name in names:\n",
    "            try:\n",
    "                tensor_names.append(name2tensor(name))\n",
    "                target_langs.append(lang2label[lang])\n",
    "            except KeyError:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_idx, test_idx = train_test_split(\n",
    "    range(len(target_langs)), \n",
    "    test_size=0.1, \n",
    "    shuffle=True, \n",
    "    stratify=target_langs\n",
    ")\n",
    "\n",
    "train_dataset = [\n",
    "    (tensor_names[i], target_langs[i])\n",
    "    for i in train_idx\n",
    "]\n",
    "\n",
    "test_dataset = [\n",
    "    (tensor_names[i], target_langs[i])\n",
    "    for i in test_idx\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(VanillaRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.in2hidden = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.in2output = nn.Linear(input_size + hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x, hidden_state):\n",
    "        combined = torch.cat((x, hidden_state), 1)\n",
    "        hidden = torch.sigmoid(self.in2hidden(combined))\n",
    "        output = self.in2output(combined)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return nn.init.kaiming_uniform_(torch.empty(1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = VanillaRNN(input_size=num_letters, hidden_size=hidden_size, output_size=num_langs)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [3000/18063], Loss: 1.6980\n",
      "Epoch [1/2], Step [6000/18063], Loss: 1.8498\n",
      "Epoch [1/2], Step [9000/18063], Loss: 0.0086\n",
      "Epoch [1/2], Step [12000/18063], Loss: 0.2665\n",
      "Epoch [1/2], Step [15000/18063], Loss: 0.1882\n",
      "Epoch [1/2], Step [18000/18063], Loss: 0.0002\n",
      "Epoch [2/2], Step [3000/18063], Loss: 0.1571\n",
      "Epoch [2/2], Step [6000/18063], Loss: 0.1640\n",
      "Epoch [2/2], Step [9000/18063], Loss: 0.7492\n",
      "Epoch [2/2], Step [12000/18063], Loss: 4.0861\n",
      "Epoch [2/2], Step [15000/18063], Loss: 0.2719\n",
      "Epoch [2/2], Step [18000/18063], Loss: 0.0030\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "print_interval = 3000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    random.shuffle(train_dataset)\n",
    "    for i, (name, label) in enumerate(train_dataset):\n",
    "        hidden_state = model.init_hidden()\n",
    "        for char in name:\n",
    "            output, hidden_state = model(char, hidden_state)\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i + 1) % print_interval == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "                f\"Step [{i + 1}/{len(train_dataset)}], \"\n",
    "                f\"Loss: {loss.item():.4f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rnn_dataset import get_loader\n",
    "\n",
    "dataloader,dataset = get_loader(\"./data/\", \"small_sentiments.csv\", batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_classifier = VanillaRNN(input_size=len(dataset.vocab), hidden_size=hidden_size, output_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [1/18063], Loss: 0.4731\n",
      "Epoch [1/100], Step [2/18063], Loss: 1.3778\n",
      "Epoch [2/100], Step [1/18063], Loss: 0.2976\n",
      "Epoch [2/100], Step [2/18063], Loss: 1.5016\n",
      "Epoch [3/100], Step [1/18063], Loss: 0.2578\n",
      "Epoch [3/100], Step [2/18063], Loss: 1.5688\n",
      "Epoch [4/100], Step [1/18063], Loss: 1.5449\n",
      "Epoch [4/100], Step [2/18063], Loss: 0.2681\n",
      "Epoch [5/100], Step [1/18063], Loss: 0.2702\n",
      "Epoch [5/100], Step [2/18063], Loss: 1.4990\n",
      "Epoch [6/100], Step [1/18063], Loss: 0.2541\n",
      "Epoch [6/100], Step [2/18063], Loss: 1.5402\n",
      "Epoch [7/100], Step [1/18063], Loss: 0.2430\n",
      "Epoch [7/100], Step [2/18063], Loss: 1.5707\n",
      "Epoch [8/100], Step [1/18063], Loss: 0.2349\n",
      "Epoch [8/100], Step [2/18063], Loss: 1.5940\n",
      "Epoch [9/100], Step [1/18063], Loss: 1.5756\n",
      "Epoch [9/100], Step [2/18063], Loss: 0.2470\n",
      "Epoch [10/100], Step [1/18063], Loss: 1.4990\n",
      "Epoch [10/100], Step [2/18063], Loss: 0.2658\n",
      "Epoch [11/100], Step [1/18063], Loss: 1.4408\n",
      "Epoch [11/100], Step [2/18063], Loss: 0.2812\n",
      "Epoch [12/100], Step [1/18063], Loss: 0.2799\n",
      "Epoch [12/100], Step [2/18063], Loss: 1.4446\n",
      "Epoch [13/100], Step [1/18063], Loss: 1.4429\n",
      "Epoch [13/100], Step [2/18063], Loss: 0.2790\n",
      "Epoch [14/100], Step [1/18063], Loss: 0.2778\n",
      "Epoch [14/100], Step [2/18063], Loss: 1.4468\n",
      "Epoch [15/100], Step [1/18063], Loss: 0.2634\n",
      "Epoch [15/100], Step [2/18063], Loss: 1.4871\n",
      "Epoch [16/100], Step [1/18063], Loss: 0.2521\n",
      "Epoch [16/100], Step [2/18063], Loss: 1.5201\n",
      "Epoch [17/100], Step [1/18063], Loss: 0.2433\n",
      "Epoch [17/100], Step [2/18063], Loss: 1.5469\n",
      "Epoch [18/100], Step [1/18063], Loss: 0.2362\n",
      "Epoch [18/100], Step [2/18063], Loss: 1.5689\n",
      "Epoch [19/100], Step [1/18063], Loss: 1.5556\n",
      "Epoch [19/100], Step [2/18063], Loss: 0.2452\n",
      "Epoch [20/100], Step [1/18063], Loss: 1.4950\n",
      "Epoch [20/100], Step [2/18063], Loss: 0.2603\n",
      "Epoch [21/100], Step [1/18063], Loss: 1.4474\n",
      "Epoch [21/100], Step [2/18063], Loss: 0.2728\n",
      "Epoch [22/100], Step [1/18063], Loss: 0.2713\n",
      "Epoch [22/100], Step [2/18063], Loss: 1.4547\n",
      "Epoch [23/100], Step [1/18063], Loss: 0.2574\n",
      "Epoch [23/100], Step [2/18063], Loss: 1.4948\n",
      "Epoch [24/100], Step [1/18063], Loss: 0.2464\n",
      "Epoch [24/100], Step [2/18063], Loss: 1.5279\n",
      "Epoch [25/100], Step [1/18063], Loss: 1.5202\n",
      "Epoch [25/100], Step [2/18063], Loss: 0.2508\n",
      "Epoch [26/100], Step [1/18063], Loss: 1.4707\n",
      "Epoch [26/100], Step [2/18063], Loss: 0.2634\n",
      "Epoch [27/100], Step [1/18063], Loss: 1.4317\n",
      "Epoch [27/100], Step [2/18063], Loss: 0.2736\n",
      "Epoch [28/100], Step [1/18063], Loss: 0.2713\n",
      "Epoch [28/100], Step [2/18063], Loss: 1.4474\n",
      "Epoch [29/100], Step [1/18063], Loss: 1.4491\n",
      "Epoch [29/100], Step [2/18063], Loss: 0.2675\n",
      "Epoch [30/100], Step [1/18063], Loss: 1.4163\n",
      "Epoch [30/100], Step [2/18063], Loss: 0.2761\n",
      "Epoch [31/100], Step [1/18063], Loss: 0.2730\n",
      "Epoch [31/100], Step [2/18063], Loss: 1.4385\n",
      "Epoch [32/100], Step [1/18063], Loss: 1.4420\n",
      "Epoch [32/100], Step [2/18063], Loss: 0.2674\n",
      "Epoch [33/100], Step [1/18063], Loss: 0.2649\n",
      "Epoch [33/100], Step [2/18063], Loss: 1.4590\n",
      "Epoch [34/100], Step [1/18063], Loss: 0.2498\n",
      "Epoch [34/100], Step [2/18063], Loss: 1.5035\n",
      "Epoch [35/100], Step [1/18063], Loss: 1.5013\n",
      "Epoch [35/100], Step [2/18063], Loss: 0.2494\n",
      "Epoch [36/100], Step [1/18063], Loss: 1.4622\n",
      "Epoch [36/100], Step [2/18063], Loss: 0.2590\n",
      "Epoch [37/100], Step [1/18063], Loss: 1.4316\n",
      "Epoch [37/100], Step [2/18063], Loss: 0.2667\n",
      "Epoch [38/100], Step [1/18063], Loss: 1.4075\n",
      "Epoch [38/100], Step [2/18063], Loss: 0.2727\n",
      "Epoch [39/100], Step [1/18063], Loss: 1.3889\n",
      "Epoch [39/100], Step [2/18063], Loss: 0.2772\n",
      "Epoch [40/100], Step [1/18063], Loss: 0.2724\n",
      "Epoch [40/100], Step [2/18063], Loss: 1.4264\n",
      "Epoch [41/100], Step [1/18063], Loss: 1.4341\n",
      "Epoch [41/100], Step [2/18063], Loss: 0.2626\n",
      "Epoch [42/100], Step [1/18063], Loss: 1.4125\n",
      "Epoch [42/100], Step [2/18063], Loss: 0.2678\n",
      "Epoch [43/100], Step [1/18063], Loss: 1.3958\n",
      "Epoch [43/100], Step [2/18063], Loss: 0.2716\n",
      "Epoch [44/100], Step [1/18063], Loss: 0.2666\n",
      "Epoch [44/100], Step [2/18063], Loss: 1.4353\n",
      "Epoch [45/100], Step [1/18063], Loss: 1.4436\n",
      "Epoch [45/100], Step [2/18063], Loss: 0.2563\n",
      "Epoch [46/100], Step [1/18063], Loss: 0.2527\n",
      "Epoch [46/100], Step [2/18063], Loss: 1.4725\n",
      "Epoch [47/100], Step [1/18063], Loss: 0.2361\n",
      "Epoch [47/100], Step [2/18063], Loss: 1.5231\n",
      "Epoch [48/100], Step [1/18063], Loss: 1.5237\n",
      "Epoch [48/100], Step [2/18063], Loss: 0.2330\n",
      "Epoch [49/100], Step [1/18063], Loss: 0.2313\n",
      "Epoch [49/100], Step [2/18063], Loss: 1.5339\n",
      "Epoch [50/100], Step [1/18063], Loss: 1.5341\n",
      "Epoch [50/100], Step [2/18063], Loss: 0.2286\n",
      "Epoch [51/100], Step [1/18063], Loss: 1.4987\n",
      "Epoch [51/100], Step [2/18063], Loss: 0.2362\n",
      "Epoch [52/100], Step [1/18063], Loss: 1.4709\n",
      "Epoch [52/100], Step [2/18063], Loss: 0.2420\n",
      "Epoch [53/100], Step [1/18063], Loss: 1.4491\n",
      "Epoch [53/100], Step [2/18063], Loss: 0.2465\n",
      "Epoch [54/100], Step [1/18063], Loss: 1.4322\n",
      "Epoch [54/100], Step [2/18063], Loss: 0.2498\n",
      "Epoch [55/100], Step [1/18063], Loss: 0.2450\n",
      "Epoch [55/100], Step [2/18063], Loss: 1.4719\n",
      "Epoch [56/100], Step [1/18063], Loss: 1.4801\n",
      "Epoch [56/100], Step [2/18063], Loss: 0.2351\n",
      "Epoch [57/100], Step [1/18063], Loss: 1.4589\n",
      "Epoch [57/100], Step [2/18063], Loss: 0.2392\n",
      "Epoch [58/100], Step [1/18063], Loss: 1.4422\n",
      "Epoch [58/100], Step [2/18063], Loss: 0.2421\n",
      "Epoch [59/100], Step [1/18063], Loss: 0.2373\n",
      "Epoch [59/100], Step [2/18063], Loss: 1.4825\n",
      "Epoch [60/100], Step [1/18063], Loss: 0.2195\n",
      "Epoch [60/100], Step [2/18063], Loss: 1.5391\n",
      "Epoch [61/100], Step [1/18063], Loss: 1.5420\n",
      "Epoch [61/100], Step [2/18063], Loss: 0.2142\n",
      "Epoch [62/100], Step [1/18063], Loss: 0.2119\n",
      "Epoch [62/100], Step [2/18063], Loss: 1.5578\n",
      "Epoch [63/100], Step [1/18063], Loss: 1.5593\n",
      "Epoch [63/100], Step [2/18063], Loss: 0.2079\n",
      "Epoch [64/100], Step [1/18063], Loss: 0.2059\n",
      "Epoch [64/100], Step [2/18063], Loss: 1.5714\n",
      "Epoch [65/100], Step [1/18063], Loss: 1.5717\n",
      "Epoch [65/100], Step [2/18063], Loss: 0.2025\n",
      "Epoch [66/100], Step [1/18063], Loss: 0.2008\n",
      "Epoch [66/100], Step [2/18063], Loss: 1.5808\n",
      "Epoch [67/100], Step [1/18063], Loss: 1.5804\n",
      "Epoch [67/100], Step [2/18063], Loss: 0.1979\n",
      "Epoch [68/100], Step [1/18063], Loss: 0.1963\n",
      "Epoch [68/100], Step [2/18063], Loss: 1.5873\n",
      "Epoch [69/100], Step [1/18063], Loss: 0.1852\n",
      "Epoch [69/100], Step [2/18063], Loss: 1.6277\n",
      "Epoch [70/100], Step [1/18063], Loss: 1.6223\n",
      "Epoch [70/100], Step [2/18063], Loss: 0.1853\n",
      "Epoch [71/100], Step [1/18063], Loss: 0.1845\n",
      "Epoch [71/100], Step [2/18063], Loss: 1.6174\n",
      "Epoch [72/100], Step [1/18063], Loss: 0.1752\n",
      "Epoch [72/100], Step [2/18063], Loss: 1.6515\n",
      "Epoch [73/100], Step [1/18063], Loss: 1.6430\n",
      "Epoch [73/100], Step [2/18063], Loss: 0.1768\n",
      "Epoch [74/100], Step [1/18063], Loss: 1.5908\n",
      "Epoch [74/100], Step [2/18063], Loss: 0.1851\n",
      "Epoch [75/100], Step [1/18063], Loss: 1.5481\n",
      "Epoch [75/100], Step [2/18063], Loss: 0.1916\n",
      "Epoch [76/100], Step [1/18063], Loss: 1.5135\n",
      "Epoch [76/100], Step [2/18063], Loss: 0.1968\n",
      "Epoch [77/100], Step [1/18063], Loss: 1.4849\n",
      "Epoch [77/100], Step [2/18063], Loss: 0.2008\n",
      "Epoch [78/100], Step [1/18063], Loss: 1.4616\n",
      "Epoch [78/100], Step [2/18063], Loss: 0.2037\n",
      "Epoch [79/100], Step [1/18063], Loss: 1.4421\n",
      "Epoch [79/100], Step [2/18063], Loss: 0.2057\n",
      "Epoch [80/100], Step [1/18063], Loss: 0.2014\n",
      "Epoch [80/100], Step [2/18063], Loss: 1.4809\n",
      "Epoch [81/100], Step [1/18063], Loss: 0.1847\n",
      "Epoch [81/100], Step [2/18063], Loss: 1.5369\n",
      "Epoch [82/100], Step [1/18063], Loss: 1.5385\n",
      "Epoch [82/100], Step [2/18063], Loss: 0.1796\n",
      "Epoch [83/100], Step [1/18063], Loss: 0.1774\n",
      "Epoch [83/100], Step [2/18063], Loss: 1.5474\n",
      "Epoch [84/100], Step [1/18063], Loss: 0.1658\n",
      "Epoch [84/100], Step [2/18063], Loss: 1.5883\n",
      "Epoch [85/100], Step [1/18063], Loss: 0.1567\n",
      "Epoch [85/100], Step [2/18063], Loss: 1.6211\n",
      "Epoch [86/100], Step [1/18063], Loss: 1.6111\n",
      "Epoch [86/100], Step [2/18063], Loss: 0.1581\n",
      "Epoch [87/100], Step [1/18063], Loss: 0.1580\n",
      "Epoch [87/100], Step [2/18063], Loss: 1.5904\n",
      "Epoch [88/100], Step [1/18063], Loss: 1.5817\n",
      "Epoch [88/100], Step [2/18063], Loss: 0.1583\n",
      "Epoch [89/100], Step [1/18063], Loss: 1.5240\n",
      "Epoch [89/100], Step [2/18063], Loss: 0.1656\n",
      "Epoch [90/100], Step [1/18063], Loss: 0.1641\n",
      "Epoch [90/100], Step [2/18063], Loss: 1.5199\n",
      "Epoch [91/100], Step [1/18063], Loss: 0.1541\n",
      "Epoch [91/100], Step [2/18063], Loss: 1.5537\n",
      "Epoch [92/100], Step [1/18063], Loss: 0.1460\n",
      "Epoch [92/100], Step [2/18063], Loss: 1.5807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [93/100], Step [1/18063], Loss: 0.1396\n",
      "Epoch [93/100], Step [2/18063], Loss: 1.5988\n",
      "Epoch [94/100], Step [1/18063], Loss: 1.5810\n",
      "Epoch [94/100], Step [2/18063], Loss: 0.1435\n",
      "Epoch [95/100], Step [1/18063], Loss: 0.1437\n",
      "Epoch [95/100], Step [2/18063], Loss: 1.5428\n",
      "Epoch [96/100], Step [1/18063], Loss: 0.1370\n",
      "Epoch [96/100], Step [2/18063], Loss: 1.5595\n",
      "Epoch [97/100], Step [1/18063], Loss: 1.5395\n",
      "Epoch [97/100], Step [2/18063], Loss: 0.1411\n",
      "Epoch [98/100], Step [1/18063], Loss: 0.1410\n",
      "Epoch [98/100], Step [2/18063], Loss: 1.4983\n",
      "Epoch [99/100], Step [1/18063], Loss: 1.4845\n",
      "Epoch [99/100], Step [2/18063], Loss: 0.1435\n",
      "Epoch [100/100], Step [1/18063], Loss: 1.4126\n",
      "Epoch [100/100], Step [2/18063], Loss: 0.1518\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(sentiment_classifier.parameters(), lr=learning_rate)\n",
    "\n",
    "num_epochs = 100\n",
    "print_interval = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (sentence, sentiment) in enumerate(dataloader):\n",
    "        hidden_state = sentiment_classifier.init_hidden()\n",
    "        \n",
    "        for word in sentence:\n",
    "            output, hidden_state = sentiment_classifier(word, hidden_state)\n",
    "        loss = criterion(output, sentiment)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(sentiment_classifier.parameters(), 1)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i + 1) % print_interval == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "                f\"Step [{i + 1}/{len(train_dataset)}], \"\n",
    "                f\"Loss: {loss.item():.4f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.0000%\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "num_samples = len(dataloader)\n",
    "\n",
    "sentiment_classifier.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (sentence, sentiment) in enumerate(dataloader):\n",
    "        hidden_state = sentiment_classifier.init_hidden()\n",
    "        for word in sentence:\n",
    "            output, hidden_state = sentiment_classifier(word, hidden_state)\n",
    "        _, pred = torch.max(output, dim=1)\n",
    "        num_correct += bool(pred == sentiment)\n",
    "\n",
    "print(f\"Accuracy: {num_correct / num_samples * 100:.4f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(tensor_sentence):\n",
    "    sentiment_classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        hidden_state = sentiment_classifier.init_hidden()\n",
    "        for word in tensor_sentence:\n",
    "            output, hidden_state = sentiment_classifier(word, hidden_state)\n",
    "        print(output)\n",
    "        _, pred = torch.max(output, dim=1)\n",
    "    sentiment_classifier.train()\n",
    "    return pred.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8004,  1.0151]])\n",
      "1\n",
      "tensor([[-0.3499,  0.6979]])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "iterator = iter(dataloader)\n",
    "print(predict_sentiment(next(iterator)[0]))\n",
    "print(predict_sentiment(next(iterator)[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
